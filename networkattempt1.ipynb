{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initilise gym enviroment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 42)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "env = gym.make('gym_connect4:connect4-v0')\n",
    "\n",
    "num_actions = env.action_space.n\n",
    "state_size = env.observation_space.n\n",
    "num_actions, state_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Network\n",
    "\n",
    "    Input:  state observation\n",
    "    \n",
    "    Output: policy distribution\n",
    "            value prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# My attempt at creating a network (just value prediction atm)\n",
    "class valueNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(valueNet, self).__init__()\n",
    "\n",
    "        self.board_width = 7\n",
    "        self.board_height = 6\n",
    "        # common layers\n",
    "        self.conv1 = nn.Conv2d(4, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        # action policy layers\n",
    "        self.act_conv1 = nn.Conv2d(128, 4, kernel_size=1)\n",
    "        self.act_fc1 = nn.Linear(4*self.board_width*self.board_height,\n",
    "                                 self.board_width*self.board_height)\n",
    "        # state value layers\n",
    "        self.val_conv1 = nn.Conv2d(128, 2, kernel_size=1)\n",
    "        self.val_fc1 = nn.Linear(2*self.board_width*self.board_height, 64)\n",
    "        self.val_fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, state_input):\n",
    "        x = torch.as_tensor(state_input, dtype=torch.float, device=dev)\n",
    "        # common layers\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        # action policy layers\n",
    "        x_act = F.relu(self.act_conv1(x))\n",
    "        x_act = x_act.view(-1, 4*self.board_width*self.board_height)\n",
    "        x_act = F.log_softmax(self.act_fc1(x_act))\n",
    "        # state value layers\n",
    "        x_val = F.relu(self.val_conv1(x))\n",
    "        x_val = x_val.view(-1, 2*self.board_width*self.board_height)\n",
    "        x_val = F.relu(self.val_fc1(x_val))\n",
    "        x_val = F.tanh(self.val_fc2(x_val))\n",
    "        return x_act, x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available()    # I am using GPU for now\n",
    "\n",
    "dev = 0\n",
    "model = valueNet().cuda(dev)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Experience Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Transition = namedtuple('Transition', \n",
    "                        'state action n_state reward done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight 32 4 3 3, but got 2-dimensional input of size [7, 6] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-88b6b7bb175f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-37d250c35892>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, state_input)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# common layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight 32 4 3 3, but got 2-dimensional input of size [7, 6] instead"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "model(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "num_episodes = 1\n",
    "\n",
    "gamma = 0.95    # discount rate\n",
    "epsilon = 0.1   # exploration rate\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act():\n",
    "    # 𝜺-greedy exploration\n",
    "    if np.random.rand() <= epsilon:\n",
    "        return np.random.choice(env.game.legal_moves)\n",
    "    \n",
    "    succ = env.game.successor_states()\n",
    "    \n",
    "    values = [(model(state), action) for action, state in succ]\n",
    "    \n",
    "    return max(values)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.step(2)\n",
    "# env.render()\n",
    "# act()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(batch):\n",
    "    states = torch.tensor([x.state for x in batch], dtype=torch.float, device=dev)\n",
    "    actions = torch.as_tensor([x.action for x in batch], dtype=torch.long, device=dev)\n",
    "    rewards = torch.as_tensor([x.reward for x in batch], dtype=torch.float, device=dev)\n",
    "    next_states = torch.as_tensor([x.n_state for x in batch], dtype=torch.float, device=dev)\n",
    "    done = torch.as_tensor([x.done for x in batch], device=dev)\n",
    "    print(states)\n",
    "    print(action)\n",
    "    print(rewards)\n",
    "    print(next_states)\n",
    "    print(done)\n",
    "    print(\"++++++++++++++++++++++++++++++\")\n",
    "    q_value = model(states)\n",
    "    next_q_value = model(next_states)\n",
    "\n",
    "    expected_q_value = rewards + gamma * next_q_value\n",
    "    \n",
    "    loss_fn = nn.MSELoss()\n",
    "    loss = loss_fn(q_value, expected_q_value)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0')\n",
      "6\n",
      "tensor([0.], device='cuda:0')\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([False], device='cuda:0')\n",
      "++++++++++++++++++++++++++++++\n",
      "training batch... got loss  tensor(5.0655e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1., -1.,  0.,  0.,  0.,  0.]],\n",
      "       device='cuda:0')\n",
      "6\n",
      "tensor([0.], device='cuda:0')\n",
      "tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1., -1.,  1.,  0.,  0.,  0.]],\n",
      "       device='cuda:0')\n",
      "tensor([False], device='cuda:0')\n",
      "++++++++++++++++++++++++++++++\n",
      "training batch... got loss  tensor(1.8771e-10, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1., -1.,  1., -1.,  1.,  0.]],\n",
      "       device='cuda:0')\n",
      "6\n",
      "tensor([0.], device='cuda:0')\n",
      "tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1., -1.,  1., -1.,  1., -1.]],\n",
      "       device='cuda:0')\n",
      "tensor([False], device='cuda:0')\n",
      "++++++++++++++++++++++++++++++\n",
      "training batch... got loss  tensor(7.2647e-09, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1., -1.,  1., -1.,  1., -1.]],\n",
      "       device='cuda:0')\n",
      "5\n",
      "tensor([0.], device='cuda:0')\n",
      "tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  1., -1.,  0.,  0.,  0.,  0.,  1., -1.,  1., -1.,  1., -1.]],\n",
      "       device='cuda:0')\n",
      "tensor([False], device='cuda:0')\n",
      "++++++++++++++++++++++++++++++\n",
      "training batch... got loss  tensor(5.4356e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  1., -1.,  0.,  0.,  0.,  0.,  1., -1.,  1., -1.,  1., -1.]],\n",
      "       device='cuda:0')\n",
      "1\n",
      "tensor([0.], device='cuda:0')\n",
      "tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  1., -1.,  1.,  0.,  0.,  0.,  1., -1.,  1., -1.,  1., -1.]],\n",
      "       device='cuda:0')\n",
      "tensor([False], device='cuda:0')\n",
      "++++++++++++++++++++++++++++++\n",
      "training batch... got loss  tensor(3.0373e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  1., -1.,  1.,  1.,  0.,  0.,  1., -1.,  1., -1.,  1., -1.]],\n",
      "       device='cuda:0')\n",
      "5\n",
      "tensor([0.], device='cuda:0')\n",
      "tensor([[ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  1., -1.,  1.,  1., -1.,  0.,  1., -1.,  1., -1.,  1., -1.]],\n",
      "       device='cuda:0')\n",
      "tensor([False], device='cuda:0')\n",
      "++++++++++++++++++++++++++++++\n",
      "training batch... got loss  tensor(2.3292e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  1., -1.,  1.,  1., -1.,  0.,  1., -1.,  1., -1.,  1., -1.]],\n",
      "       device='cuda:0')\n",
      "4\n",
      "tensor([0.], device='cuda:0')\n",
      "tensor([[ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1., -1.]],\n",
      "       device='cuda:0')\n",
      "tensor([False], device='cuda:0')\n",
      "++++++++++++++++++++++++++++++\n",
      "training batch... got loss  tensor(8.1577e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,\n",
      "          0.,  0.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1., -1.]],\n",
      "       device='cuda:0')\n",
      "2\n",
      "tensor([0.], device='cuda:0')\n",
      "tensor([[ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  1.,  0.,  0.,\n",
      "          0.,  0.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1., -1.]],\n",
      "       device='cuda:0')\n",
      "tensor([False], device='cuda:0')\n",
      "++++++++++++++++++++++++++++++\n",
      "training batch... got loss  tensor(1.7811e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  1.,  1.,  0.,\n",
      "          0.,  0.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1., -1.]],\n",
      "       device='cuda:0')\n",
      "4\n",
      "tensor([0.], device='cuda:0')\n",
      "tensor([[ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  1.,  1., -1.,\n",
      "          0.,  0.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1., -1.]],\n",
      "       device='cuda:0')\n",
      "tensor([False], device='cuda:0')\n",
      "++++++++++++++++++++++++++++++\n",
      "training batch... got loss  tensor(2.6890e-11, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  1.,  1., -1.,\n",
      "          1.,  0.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1., -1.]],\n",
      "       device='cuda:0')\n",
      "4\n",
      "tensor([0.], device='cuda:0')\n",
      "tensor([[ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  1.,  1., -1.,\n",
      "          1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1., -1.]],\n",
      "       device='cuda:0')\n",
      "tensor([False], device='cuda:0')\n",
      "++++++++++++++++++++++++++++++\n",
      "training batch... got loss  tensor(4.3254e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  1.,  1., -1.,\n",
      "          1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1., -1.]],\n",
      "       device='cuda:0')\n",
      "3\n",
      "tensor([0.], device='cuda:0')\n",
      "tensor([[ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
      "          0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0., -1.,  1.,  1., -1.,\n",
      "          1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1., -1.]],\n",
      "       device='cuda:0')\n",
      "tensor([False], device='cuda:0')\n",
      "++++++++++++++++++++++++++++++\n",
      "training batch... got loss  tensor(5.5371e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1ef3ab0510>]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEDCAYAAAAcI05xAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXiU5b3/8fedfSdkI4QAIewkgEhYBJHFBRAQ61Y5rqilCm3Vav1pjz3dbPWcam2tuOACWq3iTgniziY7SEgmBBAI20xIQgKTfZu5f38ksYiBTJKZeWb5vq6LK8lk8jzfgeTDnXtVWmuEEEJ4rgCjCxBCCHF+EtRCCOHhJKiFEMLDSVALIYSHk6AWQggPJ0EthBAezmVBrZR6VSlVopQyOeFaU5VSOWf8qVNKXe2MOoUQwtMpV82jVkpdAlQBr2utM5143TjgAJCqta5x1nWFEMJTuaxFrbVeD5Sf+ZhSqr9S6hOl1E6l1Aal1JBOXPo6YLWEtBDCX7i7j3oJ8HOt9WjgQeC5TlzjRuAtp1YlhBAeLMhdN1JKRQETgHeVUq0Ph7Z87hrgD218mVlrPf2Ma/QEhgOfurZaIYTwHG4Lappb76e11hec/Qmt9QfABw5c4wbgQ611o7OLE0IIT+W2rg+tdQVQqJS6HkA1G9nBy8xDuj2EEH7GldPz3gI2A4OVUseVUncCNwF3KqV2A/nA3A5cLw3oDaxzfrVCCOG5XDY9TwghhHPIykQhhPBwLhlMTEhI0Glpaa64tBBC+KSdO3ee1FontvU5lwR1WloaO3bscMWlhRDCJymljpzrc9L1IYQQHk6CWgghPJwEtRBCeDgJaiGE8HAS1EII4eEkqIUQwsNJUAshhIeToBZCCCfYcqiMV78uxG53/rYcEtRCCNFF1tpGfrk8h39uOUJ9k93p13fnftRCCOGT/meFieLKet6/ZwLhIYFOv760qIUQogtW5JhZkWPh3ksHckHvWJfcQ4JaCCE6yXy6lkc/MjG6b3cWTunvsvtIUAshRCfY7JpfLs/Bbtc8fcMFBAW6Lk6lj1oIITrhpQ2H2FpYzl+uG0Gf+AiX3kta1EII0UEms5WnPtvHzMxkrhud6vL7SVALIUQH1DXauG95Dt0jQvjzj4ajlHL5PaXrQwghOuCJ1Xs5UFLF63eMpXtkiFvuKS1qIYRw0Np9JSzbdJj5E9O4ZFCbp2a5hAS1EEI4oLy6gV+9l8ugHlH8vxlD3Hpv6foQQoh2aK15+P1crDWNvDZ/LGHBzl99eD7SohZCiHa8s+MYn+0p5lfTBzMsJcbt95egFkKI8zh8sprfr9zDRenx3HlxP0NqkKAWQohzaLLZuW95DkEBiqduGElAgOun4rVF+qiFEOIcnl1zgJxjp/nHvFGkxIYbVodDQa2UOgxUAjagSWud5cqihBDCaN8cPcU/vjrAj0b1Ys7IFENr6UiLeqrW+qTLKhFCCA9RXd/E/ctzSI4J4/dzM4wuR7o+hBDibH/M3sPR8hre/sl4YsKCjS7H4cFEDXymlNqplFrQ1hOUUguUUjuUUjtKS0udV6EQQrjRJ6YTvL39GPdM7s+49HijywEcD+qJWusLgZnAIqXUJWc/QWu9RGudpbXOSkx039JKIYRwlpKKOh75IJfMXjHcd9kgo8v5jkNBrbW2tLwtAT4ExrqyKCGEcDetNQ++l0tto42//XgUIUGeM3u53UqUUpFKqejW94ErAJOrCxNCCHd6ffMR1u8v5b+vHMqApCijy/keRwYTewAftuy5GgT8S2v9iUurEkIIN/q2uJI/f1zAlMGJ3Dy+r9Hl/EC7Qa21PgSMdEMtQgjhdg1Ndu59O4fI0CD+77oRbjkIoKNkep4Qwq/99fP97CmqYMkto0mKDjO6nDZ5Tm+5EEK42eaDZby4/iDzxvbmioxko8s5JwlqIYRfstY28sA7OaTFR/Kb2cOMLue8pOtDCOGX/meFieLKet6/ZwIRIZ4dhdKiFkL4nRU5ZlbkWLj30oFc0DvW6HLaJUEthPAr5tO1PPqRiQv7xLJwSn+jy3GIBLUQwm/Y7JpfLs/Bbtc8/eMLCAr0jgj0jiqFEMIJXt5wiK2F5fz2qgz6xkcaXY7DJKiFEH7BZLby5Gf7mJGRzPWjU40up0MkqIUQPq+u0cZ9y3PoHhHC49cM98jVh+fj2XNShBDCCZ5YvZcDJVW8fsdYukeGGF1Oh0mLWgjh09buK2HZpsPMn5jGJYO8c698CWohhM8qr27gV+/lMqhHFP9vxhCjy+k06foQQvgkrTUPv5+LtaaR1+aPJSw40OiSOk1a1EIIn/TujuN8tqeYB6cPYlhKjNHldIkEtRDC5xw+Wc3vVuZzUXo8d12cbnQ5XSZBLYTwKU02O/ctzyEwQPHUDSMJCPCuqXhtkT5qIYRPeXbNAXKOneaZeaNIiQ03uhynkBa1EMJnVNY18uxXB7hqZApXjUwxuhynkaAWQviMPZYKmuyaH43qZXQpTiVBLYTwGXlmKwCZvboZXIlzSVALIXxGvqWCHjGhJEaHGl2KU0lQCyF8Rp7ZynAfa02DBLUQwkfUNDRxsLSKjBQJaiGE8Eh7LBVojbSohRDCU5l8dCARJKiFED4iz1xBQlQoPWJ8ayAROhDUSqlApdQupVS2KwsSQojOyLdYyewV43WntziiIy3qe4ECVxUihBCdVddo49uSKp/snwYHg1oplQrMAl52bTlCCNFxBUUV2OzaJ2d8gOMt6r8BDwH2cz1BKbVAKbVDKbWjtLTUKcUJIYQj/jOQ6N37Tp9Lu0GtlJoNlGitd57veVrrJVrrLK11VmKid55LJoTwTiZzBd0jgunlI7vlnc2RFvVE4Cql1GHgbWCaUuoNl1YlhBAdYLJYyezVzScHEsGBoNZaP6K1TtVapwE3Al9prW92eWVCCOGA+iYb+4srfXL+dCuZRy2E8Gr7T1TRaNNk+uhAInTwhBet9VpgrUsqEUKITmjd2tRXp+aBtKiFEF7OZLESExZE7zjfHEgECWohhJczmX17IBEkqIUQXqzRZmdvkW8PJIIEtRDCi+0vrqTBZpegFkIIT5VvrgAgM8U3VyS2kqAWQnitPLOVqNAg0uIjjS7FpSSohRBey2SxMiwlhoAA3x1IBAlqIYSXarLZKSiq8OmFLq0kqIUQXulgaTV1jXaGp/p2/zRIUAshvNR3W5tKi1oIITxTntlKeHAg6YlRRpfichLUQgivlN8ykBjo4wOJIEEthPBCNrsm31Lh0xsxnUmCWgjhdQpPVlPTYCPDxxe6tJKgFkJ4ndaBxOGp0qIWQgiPZDJbCQ0KYIAfDCSCBLUQwgvlma0M7RlDUKB/RJh/vEohhM+w2zV7LBVk9vKP/mmQoBZCeJkj5TVU1jf5xUKXVhLUQgiv8t2KRD+ZmgcS1EIIL2MyWwkJDGBQj2ijS3EbCWohhFcxWawMTo4mJMh/4st/XqkQwutprTGZ/WsgESSohRBe5PipWqy1jX7VPw0S1EIIL+JPW5ueSYJaCOE18sxWggIUg5P9ZyARJKiFEF7EZKlgYI9owoIDjS7FrdoNaqVUmFJqm1Jqt1IqXyn1e3cUJnzX4ZPV2O3a6DKEl2keSLQy3M8GEsGxFnU9ME1rPRK4AJihlBrv2rKEr9p6qIwpT67l7jd2Ul3fZHQ5wosUWesor27wu4FEcCCodbOqlg+DW/5Ic0h0ykc5ZkICA/iioJhrn9/E8VM1RpckvESeH65IbOVQH7VSKlAplQOUAJ9rrbe28ZwFSqkdSqkdpaWlzq5T+ICGJjurTSe4cngyr94+BvOpWq5evJGdR8qNLk14gXyzlQAFQ5Ol66NNWmub1voCIBUYq5TKbOM5S7TWWVrrrMTERGfXKXzAxgMnOV3TyOwRKUwZnMSHiyYQGRrEvCVbeW/ncaPLEx4uz2xlQFIU4SH+NZAIHZz1obU+DawFZrikGuHTVuZaiAkLYtKgBAAGJEXz0cKJZKV158F3d/P4xwXYZJBRnIPJUuGX3R7g2KyPRKVUbMv74cBlwF5XFyZ8S12jjc/yi5mekUxo0H9aRN0jQ3jtjrHcNK4PL64/xILXd1Alg4ziLCUVdZRW1vvdQpdWjrSoewJrlFK5wHaa+6izXVuW8DXr9pdSVd/EnJEpP/hccGAAf/rRcP4wN4O1+0u59rlNHCuXQUbxH3l+dkbi2RyZ9ZGrtR6ltR6htc7UWv/BHYUJ37Jyt4W4yBAm9I8/53NuvSiNZfPHUGStZe7ijWwrlEFG0cxkrkApGNbT/wYSQVYmCjeoaWjiy4ISZmYmt3vG3aSBiXy0aCKx4cHc9PIW3tl+zE1VCk+WZ7aSnhBJZGiQ0aUYQoJauNyXBSXUNtqYPeKH3R5tSU+M4sOFExmfHs9D7+fyWPYeGWT0c/kWq98OJIIEtXCD7FwLSdGhjO0X5/DXdIsIZuntY7h9Qhovf13Ina9tp6Ku0YVVCk91sqqeImsdwyWohXCNyrpG1uwr5crhPQkMUB362qDAAH53VQZ/+lEmX397kmue28SRsmoXVSo8VevWphl+OuMDJKiFi32+p5iGJnubsz0cddO4vrx+51hOVtUzd/FGNh8sc2KFwtN9F9R+uBlTKwlq4VIrd1voFRvOhX1iu3SdCf0T+GjhRBKiQrnlla38a+tRJ1UoPJ3JXEFafAQxYcFGl2IYCWrhMqdrGtjw7Ulmj+iJUh3r9mhLWkIkHyycwMUDE/j1h3n87t/5NNnsTqhUeLI8s38PJIIEtXChT0wnaLLrLnV7nC0mLJhXbhvDnRf3Y9mmw8xfth1rrQwy+qpT1Q2YT9dKUBtdgPBd2blFpMVHkJHi3L7FwADFb2YP43+vHc6WQ2X86LmNFJ6UQUZfZLL45xmJZ5OgFi5RWlnPpoMnmTMyxSndHm358Zg+vHHnOE7XNHL14o1sPHDSJfcRxjGZKwDI9OOBRJCgFi7yiakIu8bhRS6dNS49nhWLJtIjJpRbX93GPzcfdun9hHuZLFZSu4cTGxFidCmGkqAWLrFydxGDekS55bTo3nERvH/PBKYMSuQ3K/J59KM8GmWQ0Sc0n5Ho390eIEEtXKDIWsv2I+Uub02fKTosmCW3ZvHTyem8seUoty/dxumaBrfdXziftbaRI2U1fj+QCBLUwgVW5RahNcwe0dOt9w0MUDwycyhPXj+S7YWnuHrxRg6UVLX/hcIj5Vv894zEs0lQC6fLzi0iIyWG9MQoQ+5/3ehU3lowjqr6Jn703EbW75czPL1RfutAopNnDXkjCWrhVMfKa8g5dtqpc6c7Y3TfOD5aNJHU7hHcvnQbSzcWorXswOdN8sxWUrqFER8VanQphpOgFk6VnVsEwKzh7u32aEtq9wjeu/siLhvag9+v3MOvPzTJIKMXMVmsZEi3ByBBLZxs5W4Lo/rE0jsuwuhSAIgMDeKFm0ezaGp/3tp2lPuX5xhdknBAVX0ThSerZcZHCwlq4TQHS6vYU1Th1tkejggIUPxq+hDuu2wg2blFsvueF9hjqUBrWejSSoJaOE327iKU8oxuj7bcPbk/vWLDeWzVHuxyYoxHaz3MVmZ8NJOgFk6htWZlroUxaXEkdwszupw2hQUH8tCMweRbKvhgl9nocsR55JutJEWHkhTtmd9L7iZBLZxiX3ElB0qqDJ/t0Z6rRqZwQe9Y/vLpXmoamowuR5yDbG36fRLUwilW7rYQoGBmZrLRpZyXUorfzB5KcUU9L647ZHQ5og01DU0cLK2SoD6DBLXoMq012blFTByQQIIXzHkd3TeOWSN68uL6g5yw1hldjjhLQVEldi0LXc4kQS26LM9s5UhZjduXjHfFwzOGYNfwl0/3GV2KOEvrGYnDU6VF3UqCWnRZdm4RwYGK6Rme3e1xpt5xEdwxsR/vf3OcvONWo8sRZzCZrcRHhpAcIwOJrdoNaqVUb6XUGqVUgVIqXyl1rzsKE97Bbtdk77YwaWCi1+0ZvHBqf+IjQ3hs1R5ZXu5BWgcSXXXghDdypEXdBDygtR4KjAcWKaWGubYs4S12HTuFxVrHnJHe0+3RKiYsmPsvH8TWwnI+zS82uhwB1DXa+LakSha6nKXdoNZaF2mtv2l5vxIoAHq5ujDhHVbuLiIkKIDLhvYwupROuXFMbwb1iOLx1QU0NMk+IEbbe6ISm13L0vGzdKiPWimVBowCtrqiGOFdbHbNqrwipg1OIjos2OhyOiUoMID/njWMI2U1vL75sNHl+L3WgcQMPz/M9mwOB7VSKgp4H7hPa13RxucXKKV2KKV2lJbK/r/+YGthGaWV9cz2wm6PM00elMjkQYk88+W3nKqWU2GMZDJbiY0IJrV7uNGleBSHglopFUxzSL+ptf6gredorZdorbO01lmJiYnOrFF4qOzcIiJCApk2JMnoUrrsv2cNpaq+ib9/+a3Rpfg1k8VKZooMJJ7NkVkfCngFKNBa/9X1JQlv0GizszqviEuH9iAiJMjocrpsUI9o5o3twxtbjnCwVI7vMkJ9k419JyplRWIbHGlRTwRuAaYppXJa/lzp4rqEh9t0sIxTNY3M8aJFLu25//JBhAcH8vjHBUaX4pe+La6i0aZlxkcb2m0Kaa2/BuT3EPE9K3dbiA4NYvJg3+nmSogKZdG0ATyxei8bD5xk4oAEo0vyK99tbSoDiT8gKxNFh9U32fg0/wRXZCQTGhRodDlOdfuENFK7h/PYqgJssme1W5nMVqLDgugb7xmnA3kSCWrRYev3n6SyrsnrZ3u0JSw4kIdnDqGgqIL3dh4zupwu23nkFCUV3rHxlMlSQUZKjAwktkGCWnRYdq6F2IhgLvbRroFZw3tyYZ9YnvxsP1X13rtn9SemE1z3wiZ+9q9dRpfSrkabnYKiClnocg4S1KJDahtsfL6nmJmZyQQH+ua3T/Oe1cMoraznxXUHjS6nU3YeOcW9b+8iOjSIbYfL2VZYbnRJ53WgpIqGJrvM+DgH3/xJEy6zZl8JNQ025njYAbbONqpPd+ZekMKS9YewnK41upwOOVRaxV2vbadntzA+vncS8ZEhLF5zwOiyzkvOSDw/CWrRISt3W0iICmVcerzRpbjcQzOGAN61Z3VpZT23Ld2GUopl88eS2j2COy7ux7r9pd8tz/ZE+WYrkSGB9IuPNLoUjyRBLRxWVd/EV3tLmDU8mcAA3x/w6RUbzl2T+vHhLjM5x04bXU67ahqauPO17ZRW1vPKbVmkJTSH3i0X9SU6LMijW9V5ZisZKd0I8IPvq86QoBYO+2JPMfVNdmZ7+AG2znTPlAEkRIXwWLZn71ndZLPzs3/twmS28o95FzKqT/fvPhcTFsxtF6XxSf4JDpRUGlhl22x2zZ6iCjJkocs5SVALh2XnWujZLYzRZ4SAr4sKDeKBKwaz48gpVptOGF1Om7TW/GaFia/2lvCHuZlcPuyHW87ecXE/woICeW6t5w2OHiytoq7RLjM+zkOCWjjEWtPIuv2lzBre0+9+Pb0hqzdDkqN5fHUB9U02o8v5gcVrDvDWtmMsmtqfm8f3bfM5cZEhzBvbhxU5Fo6V17i5wvMzyUBiuySohUM+3XOCRptmjh91e7QKDFA8OmsYx8preW3TYaPL+Z73dh7nyc/2c82oXjx4xeDzPnfBJekEKHhxvWe1qvPMVsKCA+ifGGV0KR5Lglo4ZOVuC33iIhjhpydDXzwwgWlDkvjHlwcoq6o3uhwANnxbysPv5zJxQDxPXDui3RV9yd3CuG50Ku/sOO5RqxXzzRUM6xnjFwPUnSVBLdpVVlXPpoNlzB7R06+X9/76yiHUNNr42xfG71mdb7FyzxvfMCApiudvHk1IkGM/yndP7k+Tzc7LXxe6uELH2O2afItVuj3aIUEt2rXadAKbXTPbxxe5tGdAUjQ3jevDv7Yd5dti42ZPHD9Vw/yl24kOC2LZ/LHEdOAYtL7xkcwZmcIbW454xGk2hWXVVDfYJKjbIUEt2rVyt4X+iZEM7RltdCmGu++yQUSEBPJng/asttY0cvvS7dQ22lg2fyzJ3cI6fI2FUwZQ02BjmQf0t5tka1OHSFCL8yquqGPb4XLmjEzx626PVnGRIfxi2kDW7Ctl/X73ng1a12jjJ//cwdGyGpbcksXg5M79xzk4OZrLh/Vg2abDhm86ZTJbCQkKYGAPGUg8HwlqcV6rcovQGr/v9jjTrRP60icugj+tKqDJZnfLPe12zQPv7mZbYTl/uX4EF/Xv2hL+n00dgLW2kTe3HHFShZ1jMlcwNDnaZzf4chb52xHnlZ1rYWjPGAYkSYunVWhQII/MHMK+4kre2XHcLfd8fHUBq3KLeGTmEOZe0KvL1xvZO5ZJAxN4aUMhdY3GzA3XWjcfZiv90+2SoBbndPxUDd8cPc1sHzoX0VlmZCYzNi2Ov36+j8q6Rpfe69WvC3lpQyG3XdSXBZekO+26C6cM4GRVPe/uMOaAhKPlNVTWNUlQO0CCWpzTqtwiAJ/f0rQzlFI8OnsoJ6saeN6Fy7JX5xXxx1V7mJ7Rg/+Zk+HUcYLx6XGM7tudF9YdotFNXThnat3aVJaOt0+CWpzTylwLI1O70UfOsGvTiNRYrhnVi5e/LuT4Kecvy95xuJx7l+cwqncsf79xlNMXhCilWDS1P+bTtazIsTj12o4wmSsIDlQykOgACWrRpsKT1ZjMFX65ZLwjHpw+mAAF//uJc/esPlBSxV2v7yA1NpyXbxtDWLBrDhGeOjiJoT1jeG7tAbcf5msyWxmcHO1zByS7ggS1aFP27uYW1pXDpX/6fFJiw1kwKZ2Vuy3sPHLKKdcsqazj9qXbCApo3vw/LjLEKddtS2ur+lBpNZ+4cXfA7wYSZf60QySoRZuyc4sYk9adlNhwo0vxeD+d3J+k6FAeW9X1Paur65u4Y9l2yqoaePX2MW7pdpqZ2ZP0xEgWrzngtj23j5+q5XRNowwkOkiCWvzA/uJK9hVXytxpB0WGBvHg9MHsOnqa7JYB2M5otNlZ+OY3FBRV8txNFzIiNdaJVZ5bYIDinsn92VNUwdp97lnEk2+RrU07QoJa/ED2bgsBCmYOTza6FK9x7YWpDOsZwxOr93ZqXrLWmkc/NLFufymPXZ3J1CFJLqjy3K4e1YteseE866ZWtclcQWCAYkgnV1f6Gwlq8T1aa1bmFjE+PZ6k6I7vI+GvmvesHor5dC2vbuz4znTPfHmA5TuO8YtpA5g3to8LKjy/4MAAfjo5nZ1HTrG1sNzl98szWxmYFOWyQVJf025QK6VeVUqVKKVM7ihIGCvfUkHhyWqZ7dEJEwYkcNnQHjy35iCllY7vWf3OjmM8/cV+rr0wlfsvH+TCCs/vhqzeJESFuvwQXK01JrOsSOwIR1rUy4AZLq5DeIiVuRaCAhQzMqTbozN+feUQ6hptPP3Ffoeev3ZfCY98kMekgQk8ce1wQze+CgsO5K5J/djw7Ul2u/DU9RMVdZRVN8hClw5oN6i11usB1/8uJAyntSZ7dxEXD0yguwunhPmy9MQobrmoL29vO8q+E+ffs9pktrLwzW8Y3COa528e7REbE900rg8xYUE8t9Z1rWqTuQKATDl13GFO+85QSi1QSu1QSu0oLXXv9o/COXYdO435dK3M9uiiey8dSHRYMH86z57Vx8pruH3pdrpHhLBs/hiiQoPcWOG5RYcFc/vEfnyaX8x+Fx2OkGe2EqBgaE8Jakc5Lai11ku01lla66zExERnXVa4UfbuIkICA7gio4fRpXi12IgQfnHpQNbvL2XNvpIffP50TQO3Ld1GQ5ON1+4YQ1KMZw3azp+QRkRIIM+5qK8632ylf2IUESGe8Z+TNzD+dy3hEex2zao8C5MHJ3boaCfRtlvG9yUt/od7Vtc12rjrtR0cL6/l5dvGMCDJ86andY8M4aZxffj3bgtHy5y/h0me2Sr90x0kQS0A2H64nOKKepnt4SQhQQE8cuVQDpRU8db25m1E7XbN/ctz2HHkFE//+ALG9oszuMpz+8mkdIICAnh+nXN3BiypqKOksp4MCeoOcWR63lvAZmCwUuq4UupO15cl3G1lroWw4AAudfNCC192xbAejE+P4+nP91NR18hjqwpYbTrBo7OGMsvD9/hOignj+qxU3t95nBPWOqdd12SRrU07w5FZH/O01j211sFa61St9SvuKEy4T5PNzuq8E1w6tAeRHjKo5QuUUjw6axinahq48cUtvLqxkDsm9uOuSc7b/N+V7p7cH5vWvLThkNOuaTJXoBQMS5GBxI6Qrg/B5kNllFU3MMfDW3neKLNXN669MJU9RRVcOTyZR2cNNbokh/WOi2DuyBT+tfUo5dUNTrlmntlKv4RIj5nl4i0kqAXZu4uICg1iymDp9nCFR2cN5XdzhvHXGy4gwMmb/7vawqn9qWuysbQTy+Lbkm+WrU07Q4LazzU02VltKuLyYT1k3wUXiY0I4faJ/bzy73dAUjTThyWzbNPhLp8NWVZVj8VaJwtdOkGC2s9t+LaUirom5oyUbg/RtkVTB1BZ18Q/txzp0nVMltYVidKi7igJaj+XnVtEt/BgLh4gi5RE24andmPyoERe2VBIbUPHt3BtZWo5zDZDuj46TILaj9U12vgs/wQzMpIJCZJvBXFui6YOoKy6geXbj3b6Giazlb7xEXQLlwVVHSU/nX5s7b4SqhtszJZuD9GOsf3iGJsWx4vrD9HQZG//C9ogZyR2ngS1H1u5u4j4yBAuSo83uhThBRZO7U+RtY6Pdpk7/LWnaxo4Vl4r/dOdJEHtp6rrm/hybzEzhycT5AHbawrPN3lQIpm9Ynh+3UFs9o4d15Vvka1Nu0J+Qv3UFwXF1DXamSNbmgoHKaVYNGUAhSer+TivY4f45rUMJErXR+d4VFDXNDQZXYLPq2u08eK6gzz6kYmUbmGMSfPcjYGE55mekcyApCgWd/AQXJPZSq/YcDmQopM8Jqjrm2zMfuZrfvXubk5WOX7enHCM3a5ZkWPm0qfW8fjqvWT17c7rd47zupVywlgBAYqFU/qz90QlX+394V7b52KSrU27xGOC2m6Hy4f14MNdZqY+uZalGwu/t4+v6LzNB8uYu3gj976dQ7fwYN68a79J+48AAApvSURBVBxL549lQFKU0aUJLzRnZAqp3cN51sFWdUVdI4fLaqR/ugs8JqjDQwJ55MqhfHLfJVzQO5bfr9zDrGe+ZvPBMqNL81oHSiq567XtzHtpCyer6vnrDSPJ/vnFTByQYHRpwosFBwZw9+T+7Dp6ms2H2v/5zDfLisSu8pigbjUgKYrX7xjLCzePpqq+iXkvbeFn//qGImut0aV5jdLKev77wzym/20DWw+V89CMwax5cArXXJgqXR3CKa4bnUpSdCiLHTiuK98iKxK7yiP3GlRKMSMzmcmDEnlh3UFeWHeQLwtK+Nm0Adw1qR+hQd63uY071DbYeHnDIV5Yd5D6Jjs3j+vDLy4dSHxUqNGlCR8TFhzITyal86ePC9h19BSj+nQ/53NNZivJMWEkRsv3YWd5XIv6TOEhgdx/+SC++OVkJg1M4C+f7mP60+tZ04FBDH9gs2ve2XGMKU+u4anP93PxwAQ+u/8Sfj83U0JauMx/jetDbEQwi9ec/7iuPLNVuj26yKODulXvuAiW3JrFa3eMJUAp5i/bzl2vbedIWbXRpRlu/f5SZj2zgYfey6Vnt3DevfsiXrwli/REGSgUrhUZGsT8Cf34oqCYvScq2nxOdX0Th05Wy0BiF3lFULeaPCiRT+67hIdnDmHTwTIuf3o9T322r0s7enmrgqIKbnllK7e+uo2aBhvP/tcoPlw4QeZFC7e6fUIakSGBPHeOVvWeogq0ljMSu8qrghqaT3e+e3J/vnpgCjMzk/nHVwe49Km1fJxX1KEJ+N7qhLWOX727myuf2UDucSuPzhrK57+8hNkjUlBKBgqFe3WLCObmi/qSnWvh8Mkf/obburWpdH10jdcFdavkbmH8/cZRLF8wnpjwYBa++Q03v7KVb4srjS7NJarqm3jqs31MeXINK3Is/GRSOut/NZW7JqXL4Kow1F0XpxMcGMAL637Yqs4zW0mMDqVHTJgBlfkOrw3qVuPS48n++cX8YW4GecetzPz7Bv6YvYeKLh4b5CmabHb+ueUIU/6yhn98dYArhiXz5QOT+fWVQ+kWIfv6CuMlRofy4zG9ef+b41hOf38abb65gkw5cbzLvD6oAYICA7j1ojTWPDiF67NSeXVjIdOeXMf7O49j7+AuX55Ca83ne4qZ/rf1/OYjE+mJUaxYNJFn5o2id1yE0eUJ8T0LLklHa3hpw6HvHqttsPFtSaX0TzuBTwR1q/ioUB6/ZgQfLZxIavdwHnh3N9e9sOm7fjJvkXv8NDcu2cJPXt+BBl66NYvlC8Yzsnes0aUJ0abU7hFcPaoXb207+t1ePQUnKrBryJCg7jKfCupWI3vH8sE9E/i/60ZwpKyGOc9+za8/zONUdYPRpZ3XsfIa7n17F1c9u5EDJVX88epMPr3vEi4f1kMGCoXHu2dKf+qb7CzdWAj8ZyBRWtRd55ErE50hIEBxQ1Zvpmck87cv9vP65iN8nFfEg1cMZt7YPgR60FJqa00ji9ceYNnGwwQEwM+mDuCnk9OJDpM+aOE9+idGcWVmT17fdIQFl/THZLYSFxlCz24ykNhVPhvUrbqFB/PbORncOKYPv/23iUc/MvHWtqP8/qoMstw859hu15yubaS8up6TVQ2UVzdwqLSKl78uxFrbyLUXpvLAFYPo2S3crXUJ4SwLp/ZnVV4R/9x8mDxzBZm9uslvg07gUFArpWYAfwcCgZe11k+4tCoXGJwczVs/GU92bhF//riA617YzDWjevHwzCEkdXLqkM2uOV3TQFl1A2UtwVteXf+9j8uq65vfVjVwqqaBtsY2Jw1M4JGZQxkmo+PCy2WkdGPakCRe+bqQyrompg5ONLokn9BuUCulAoHFwOXAcWC7UurfWus9ri7O2ZRSzBmZwrQhSSxec4CXNxTy2Z5i7r10ILdPTCNAKU7VNIdqa8CWVze0tH7/E7hlLY+fqmngXGtsYiOCiYsMIT4yhPSEKLLSmt+PiwwhPir0u/cTokJlsxrhUxZN7c+1z28GZKGLszjSoh4LHNBaHwJQSr0NzAW8LqhbRYYG8dCMIVyf1Zs/rMznTx8X8NfP91PXZDtn8Hb/LnhDGZAYRXy//wRvXFQoCZEhxEU1f9w9IoRgOTBW+KnRfeMYnx7HlkPlMpDoJI4EdS/g2BkfHwfGnf0kpdQCYAFAnz59nFKcq/VLiGTp/LF8tbeYdftK6RZxZqu3OZSbgzdYTuoWogN+d1UGq3KLSO0u4y3O4EhQtzUS8IN2p9Z6CbAEICsry6tWmUwb0oNpQ3oYXYYQPmNIcgxDkmXMxVkcaSYeB3qf8XEqYHFNOUIIIc7mSFBvBwYqpfoppUKAG4F/u7YsIYQQrdrt+tBaNymlfgZ8SvP0vFe11vkur0wIIQTg4DxqrfXHwMcurkUIIUQbZCqDEEJ4OAlqIYTwcBLUQgjh4SSohRDCwylXHAirlCoFjnTyyxOAk04sxxvIa/Z9/vZ6QV5zR/XVWre5i5VLgrorlFI7tNZZRtfhTvKafZ+/vV6Q1+xM0vUhhBAeToJaCCE8nCcG9RKjCzCAvGbf52+vF+Q1O43H9VELIYT4Pk9sUQshhDiDBLUQQng4jwlqpdQMpdQ+pdQBpdTDRtfjakqp3kqpNUqpAqVUvlLqXqNrchelVKBSapdSKtvoWtxBKRWrlHpPKbW35d/7IqNrcjWl1P0t39cmpdRbSqnOnSDtwZRSryqlSpRSpjMei1NKfa6U+rblbXdn3MsjgvqMA3RnAsOAeUqpYcZW5XJNwANa66HAeGCRH7zmVvcCBUYX4UZ/Bz7RWg8BRuLjr10p1Qv4BZCltc6keXvkG42tyiWWATPOeuxh4Eut9UDgy5aPu8wjgpozDtDVWjcArQfo+iytdZHW+puW9ytp/uHtZWxVrqeUSgVmAS8bXYs7KKVigEuAVwC01g1a69PGVuUWQUC4UioIiMAHT4XSWq8Hys96eC7wWsv7rwFXO+NenhLUbR2g6/Oh1UoplQaMArYaW4lb/A14CLAbXYibpAOlwNKW7p6XlVKRRhflSlprM/AkcBQoAqxa68+Mrcptemiti6C5MQYkOeOinhLUDh2g64uUUlHA+8B9WusKo+txJaXUbKBEa73T6FrcKAi4EHheaz0KqMZJvw57qpZ+2blAPyAFiFRK3WxsVd7NU4LaLw/QVUoF0xzSb2qtPzC6HjeYCFyllDpMc/fWNKXUG8aW5HLHgeNa69bflt6jObh92WVAoda6VGvdCHwATDC4JncpVkr1BGh5W+KMi3pKUPvdAbpKKUVzv2WB1vqvRtfjDlrrR7TWqVrrNJr/jb/SWvt0S0trfQI4ppQa3PLQpcAeA0tyh6PAeKVURMv3+aX4+ADqGf4N3Nby/m3ACmdc1KEzE13NTw/QnQjcAuQppXJaHvt1y/mUwrf8HHizpRFyCJhvcD0upbXeqpR6D/iG5tlNu/DB5eRKqbeAKUCCUuo48FvgCeAdpdSdNP+Hdb1T7iVLyIUQwrN5SteHEEKIc5CgFkIIDydBLYQQHk6CWgghPJwEtRBCeDgJaiGE8HAS1EII4eH+P6d/FiPkLOcvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "memory = []\n",
    "memory.clear()\n",
    "loss = []\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    \n",
    "    for t in range(10000):\n",
    "        # Choose an action\n",
    "        action = act()\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        memory.append(Transition(state, action, new_state, reward, done))\n",
    "        \n",
    "        state = new_state\n",
    "        \n",
    "        if len(memory) > batch_size:\n",
    "            batch = random.sample(memory, batch_size)\n",
    "            l = train(batch)\n",
    "            loss.append(l)\n",
    "            print(\"training batch... got loss \", l)\n",
    "            memory.clear()\n",
    "            \n",
    "        if done:\n",
    "#             print(\"Episode finished after {} timesteps. Player {} wins\".format(t+1, env.game.winner))\n",
    "#             env.game.show()\n",
    "            break\n",
    "    \n",
    "env.close()\n",
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Connect4' object has no attribute 'possible_moves'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3f48e8ac8683>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/gym-tictactoe/gym_connect4/envs/connect4_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpossible_moves\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m       \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Connect4' object has no attribute 'possible_moves'"
     ]
    }
   ],
   "source": [
    "# Take only greedy actions\n",
    "epsilon = 0\n",
    "\n",
    "start, done = env.reset(), False\n",
    "\n",
    "while not done:\n",
    "    action = act(state)\n",
    "    state, reward, done, info = env.step(action)\n",
    "    env.game.show()\n",
    "    print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class DQNAgent():\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        \n",
    "        self.gamma = 0.95    # discount rate\n",
    "        self.epsilon = 1.0   # exploration rate\n",
    "        self.epsilon_min = 0.001\n",
    "        self.epsilon_decay = 0.99995\n",
    "        self.learning_rate = 0.01\n",
    "        \n",
    "        self.model = self._build_model()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    def _build_model(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        return nn.Sequential(\n",
    "                nn.Linear(self.state_size, 32),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(32, 52),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(52, 32),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(32, self.action_size))\n",
    "\n",
    "    def act(self, state):\n",
    "        self.decay()\n",
    "        # Explore\n",
    "        print(self.epsilon)\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return np.random.choice(action_space_size)\n",
    "            \n",
    "        # Greedy\n",
    "        state = torch.FloatTensor(state)\n",
    "        act_values = self.model(state)\n",
    "        return act_values.argmax().item()\n",
    "    \n",
    "    def decay(self):\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "    \n",
    "    def train(self, state, new_state, action, reward):\n",
    "        state = torch.FloatTensor(state)\n",
    "        reward = torch.tensor([])\n",
    "        print(reward, type(reward))\n",
    "        \n",
    "        q_value = self.model(state)[action]\n",
    "        \n",
    "        loss = self.loss(q_value, reward)\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        print(loss.item(), q_value, reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 <itertools._grouper object at 0x7f30d470fa90>\n",
      "0 <itertools._grouper object at 0x7f30e46bd710>\n",
      "2 <itertools._grouper object at 0x7f30e46bdb90>\n",
      "4 <itertools._grouper object at 0x7f30d4705a10>\n",
      "2 <itertools._grouper object at 0x7f30d4705650>\n"
     ]
    }
   ],
   "source": [
    "x = [1, 1, 1, 0, 2, 4, 2, 2]\n",
    "from itertools import groupby\n",
    "for k, g in groupby(x):\n",
    "    print(k, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 4, 5, 6, 6, 4]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = {1:[1,2, 4], 2:[5,6 ,6], 3:[4]}\n",
    "[v for col in x.values() for v in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class connect4:\n",
    "    def __init__(self):\n",
    "        self.board = {1: [0]*6,\n",
    "                      2: [0]*6,\n",
    "                      3: [0]*6,\n",
    "                      4: [0]*6,\n",
    "                      5: [0]*6,\n",
    "                      6: [0]*6,\n",
    "                      7: [0]*6}\n",
    "        self.possible_moves = [i for i in range(1, 8)]\n",
    "        self.player = 0\n",
    "        self.winner = None\n",
    "        \n",
    "    def make_move(self, move):\n",
    "        if move not in self.possible_moves:\n",
    "            raise ValueError(\"move is not possible\")\n",
    "            \n",
    "        # Switch the player and play their move in the top of the specified column\n",
    "        self.player = 1 if self.player != 1 else 2\n",
    "        top_of_col = self.board[move].index(0)\n",
    "        self.board[move][top_of_col] = self.player\n",
    "        \n",
    "        # Players have reached the top of column so remove it from possible actions\n",
    "        if top_of_col >= 5:\n",
    "            self.possible_moves.remove(move)\n",
    "            \n",
    "        if self.check_winner(move, top_of_col):\n",
    "            self.winner = self.player\n",
    "            \n",
    "    def check_winner(self, col, row):\n",
    "        # just to keep variable names short\n",
    "        val = self.player\n",
    "        brd = self.board\n",
    "\n",
    "        # check right \n",
    "        if col <= 4:\n",
    "            # Horizontal\n",
    "            if brd[col+1][row] == brd[col+2][row] == brd[col+3][row] == val:\n",
    "                return True\n",
    "            # Diagonal Down\n",
    "            if row >= 3 and brd[col+1][row-1] == brd[col+2][row-2] == brd[col+3][row-3] == val:\n",
    "                return True\n",
    "            # Diagonal Up\n",
    "            if row <= 2 and brd[col+1][row+1] == brd[col+2][row+2] == brd[col+3][row+3] == val:\n",
    "                return True\n",
    "        \n",
    "        # check left\n",
    "        if col >= 4:\n",
    "            # Horizontal\n",
    "            if brd[col-1][row] == brd[col-2][row] == brd[col-3][row] == val:\n",
    "                return True\n",
    "            # Diagonal Down\n",
    "            if row >= 3 and brd[col-1][row-1] == brd[col-2][row-2] == brd[col-3][row-3] == val:\n",
    "                return True\n",
    "            # Diagonal Up\n",
    "            if row <= 2 and brd[col-1][row+1] == brd[col-2][row+2] == brd[col-3][row+3] == val:\n",
    "                return True\n",
    "            \n",
    "        # check vertical\n",
    "        return any(1 for key, group in groupby(brd[col]) if len(list(group)) > 3 and key == val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "[0, 2, 0, 0, 0, 0, 0]\n",
      "[0, 1, 0, 0, 0, 0, 0]\n",
      "[0, 2, 0, 0, 0, 0, 0]\n",
      "[0, 1, 0, 0, 0, 0, 0]\n",
      "[0, 2, 0, 0, 0, 0, 2]\n",
      "[0, 1, 1, 1, 1, 0, 2]\n"
     ]
    }
   ],
   "source": [
    "game = connect4()\n",
    "print(game.winner)\n",
    "game.make_move(2)\n",
    "print(game.winner)\n",
    "game.make_move(2)\n",
    "print(game.winner)\n",
    "game.make_move(2)\n",
    "print(game.winner)\n",
    "game.make_move(2)\n",
    "game.make_move(2)\n",
    "game.make_move(2)\n",
    "print(game.winner)\n",
    "game.make_move(3)\n",
    "game.make_move(7)\n",
    "game.make_move(4)\n",
    "game.make_move(7)\n",
    "game.make_move(5)\n",
    "\n",
    "for x in range(5, -1, -1):\n",
    "    print([game.board[k][x] for k in game.board])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe:\n",
    "    \"\"\"\n",
    "    Board is indexed:\n",
    "        [0, 1, 2,\n",
    "         3, 4, 5,\n",
    "         6, 7, 8]\n",
    "         \n",
    "         and contains either 0 or the player number (1 or 2)\n",
    "         \n",
    "    player represents the player who last moved\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.board = [0 for i in range(9)]\n",
    "        self.possible_moves = [i for i in range(9)]\n",
    "        self.player = 0\n",
    "    \n",
    "    def make_move(self, move):\n",
    "        assert move in self.possible_moves\n",
    "        \n",
    "        self.player = 1 if self.player != 1 else 2\n",
    "        self.board[move] = self.player\n",
    "        self.possible_moves.remove(move)\n",
    "        \n",
    "    def winner(self):\n",
    "        if all(self.board):\n",
    "            return 0\n",
    "        \n",
    "        lines = ((0,1,2),\n",
    "                 (3,4,5),\n",
    "                 (6,7,8),\n",
    "                 (0,3,6),\n",
    "                 (1,4,7),\n",
    "                 (2,5,8),\n",
    "                 (0,4,8),\n",
    "                 (2,4,6))\n",
    "        \n",
    "        for i, j, k in lines:\n",
    "            player = self.board[i]\n",
    "            if player and player == self.board[j] == self.board[k]:\n",
    "                return player\n",
    "            \n",
    "        return -1\n",
    "    \n",
    "    def render(self):\n",
    "        print(self.board[:3])\n",
    "        print(self.board[3:6])\n",
    "        print(self.board[6:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = TicTacToe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-24f5383632d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwhile\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwinner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter a move: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\nand the winner is: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwinner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "while x.winner() is -1:\n",
    "    x.render()\n",
    "    x.make_move(int(input(\"Enter a move: \")))\n",
    "    \n",
    "print(\"\\n\\nand the winner is: {}\".format(x.winner()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
